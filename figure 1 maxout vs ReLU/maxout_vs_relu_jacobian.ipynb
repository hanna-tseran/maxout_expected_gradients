{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of  the expectation of the directional derivative of the input-output map $\\mathbb{E}[|| \\mathbf{J}_{\\mathcal{N}} (\\mathbf{x}) \\mathbf{u} ||^2]$ for width-2 maxout and ReLU networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - It takes several minutes to compute the figures.\n",
    "\n",
    " - In the paper we used maxout networks of depths $L = 2, 4, 6, 11$ and ReLU networks pf depth $L = 6$.\n",
    "The number of hidden layers then equals $L-1$.\n",
    "\n",
    " - To obtain the same images as in the paper set **weight_samples** and **num_steps** to the values specified in the figure description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from matplotlib import ticker\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maxout network\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(80519)\n",
    "\n",
    "L = 4 # Network depth\n",
    "weight_samples = 100 # Number of initializations of the network used to estimate the expectation\n",
    "num_steps = 50 # Total number of points in the input grid is num_steps x num_steps\n",
    "\n",
    "K = 5\n",
    "WIDTH = 2\n",
    "\n",
    "x_list = np.linspace(-1000, 1000, num_steps)\n",
    "y_list = np.linspace(-1000, 1000, num_steps)\n",
    "\n",
    "second_moments_maxout = np.asarray([[0. for _ in range(num_steps)] for _ in range(num_steps)])\n",
    "\n",
    "u = np.random.normal(loc=0., scale=1, size=WIDTH)\n",
    "u = u / np.linalg.norm(u)\n",
    "\n",
    "for xi, x in enumerate(x_list):\n",
    "    for yi, y in enumerate(y_list):\n",
    "        input_x = np.asarray([x, y])\n",
    "    \n",
    "        jx_array = []    \n",
    "        for _ in range(weight_samples):            \n",
    "            x0 = input_x\n",
    "            run_weights = []\n",
    "            for _ in range(L - 1):\n",
    "                weights = np.random.normal(loc=0., scale=1., size=[WIDTH, K, WIDTH])\n",
    "                biases = np.random.normal(loc=0., scale=1., size=[WIDTH, K])\n",
    "                argmax = np.argmax(np.dot(weights, x0) + biases, axis=-1)\n",
    "                x0 = np.max(np.dot(weights, x0) + biases, axis=-1)\n",
    "                chosen_weights = [w[a] for w,a in zip(weights, argmax)]\n",
    "                run_weights.append(np.asarray(chosen_weights))\n",
    "            \n",
    "            # Last linear layer\n",
    "            weights = np.random.normal(loc=0., scale=1., size=[WIDTH, WIDTH])\n",
    "            run_weights.append(np.asarray(weights))\n",
    "\n",
    "            # Multiply the weights chosen based on the maxout to obtain the Jacobian\n",
    "            res = run_weights[-1]\n",
    "            for w in reversed(run_weights[:-1]):\n",
    "                res = np.dot(res, w)\n",
    "            \n",
    "            # Append the squared norm of the directional derivative of the input-output map\n",
    "            jx_array.append(np.dot(res, u)**2)    \n",
    "            \n",
    "        second_moments_maxout[xi][yi] = np.mean(jx_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "fig = plt.figure(figsize=(10.7, 8), dpi=100)\n",
    "ax = fig.add_subplot(111)\n",
    "ax.tick_params(axis='both', which='major', labelsize=36)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=36)\n",
    "\n",
    "plt.xlabel(\"$\\mathbf{x}_0$\", size=40)\n",
    "plt.ylabel(\"$\\mathbf{x}_1$\", size=40)\n",
    "plt.margins(x=0)\n",
    "\n",
    "plt.xticks([-800, 0, 800])\n",
    "plt.yticks([-800, 0, 800])\n",
    "\n",
    "cp = ax.contourf(x_list, y_list, second_moments_maxout, cmap='Paired', levels=100)\n",
    "ticks = [round(np.min(second_moments_maxout), 0)\n",
    "         + i * round((np.max(second_moments_maxout) - np.min(second_moments_maxout)) / 4, 0)\n",
    "         for i in range(5)]\n",
    "cbar = fig.colorbar(cp, ticks=ticks)\n",
    "cbar.ax.tick_params(labelsize=36)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'maxout_jacobian_depth_{L}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(80519)\n",
    "\n",
    "L = 6 # Network depth\n",
    "weight_samples = 100 # Number of initializations of the network used to estimate the expectation\n",
    "num_steps = 50 # Total number of points in the input grid is num_steps x num_steps\n",
    "\n",
    "K = 5\n",
    "WIDTH = 2\n",
    "\n",
    "x_list = np.linspace(-1000, 1000, num_steps)\n",
    "y_list = np.linspace(-1000, 1000, num_steps)\n",
    "\n",
    "second_moments_relu = np.asarray([[0. for _ in range(num_steps)] for _ in range(num_steps)])\n",
    "u = np.random.normal(loc=0., scale=1, size=WIDTH)\n",
    "u = u / np.linalg.norm(u)\n",
    "\n",
    "for xi, x in enumerate(x_list):\n",
    "    for yi, y in enumerate(y_list):\n",
    "        input_x = np.asarray([x, y])\n",
    "        jx_array = []   \n",
    "        \n",
    "        for _ in range(weight_samples):            \n",
    "            x0 = input_x\n",
    "            run_weights = []\n",
    "            for _ in range(L - 1):\n",
    "                weights = np.random.normal(loc=0., scale=1., size=[WIDTH, WIDTH])\n",
    "                biases = np.random.normal(loc=0., scale=1., size=[WIDTH])\n",
    "                chosen_weights = [w if np.dot(w, x0) + b > 0 else np.zeros(WIDTH)\n",
    "                                  for w, b in zip(weights, biases)]\n",
    "                run_weights.append(np.asarray(chosen_weights))\n",
    "                \n",
    "                x0 = [np.dot(w, x0) + b if np.dot(w, x0) + b > 0 else 0\n",
    "                                  for w, b in zip(weights, biases)]\n",
    "            \n",
    "            # Last linear layer\n",
    "            weights = np.random.normal(loc=0., scale=1., size=[WIDTH, WIDTH])\n",
    "            run_weights.append(np.asarray(weights))\n",
    "\n",
    "            # Multiply the weights chosen based on the ReLU to obtain the Jacobian\n",
    "            res = run_weights[-1]\n",
    "            for w in reversed(run_weights[:-1]):\n",
    "                res = np.dot(res, w)\n",
    "            \n",
    "            # Append the squared norm of the directional derivative of the input-output map\n",
    "            jx_array.append(np.dot(res, u)**2)    \n",
    "            \n",
    "        second_moments_relu[xi][yi] = np.mean(jx_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "fig = plt.figure(figsize=(10.7, 8), dpi=100)\n",
    "ax = fig.add_subplot(111)\n",
    "ax.tick_params(axis='both', which='major', labelsize=36)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=36)\n",
    "\n",
    "plt.xlabel(\"$\\mathbf{x}_0$\", size=40)\n",
    "plt.ylabel(\"$\\mathbf{x}_1$\", size=40)\n",
    "plt.margins(x=0)\n",
    "\n",
    "plt.xticks([-800, 0, 800])\n",
    "plt.yticks([-800, 0, 800])\n",
    "\n",
    "cp = ax.contourf(x_list, y_list, second_moments_relu, cmap='Paired', levels=100)\n",
    "ticks = [round(np.min(second_moments_relu), 0)\n",
    "         + i * round((np.max(second_moments_relu) - np.min(second_moments_relu)) / 4, 0)\n",
    "         for i in range(5)]\n",
    "cbar = fig.colorbar(cp, ticks=ticks)\n",
    "cbar.ax.tick_params(labelsize=36)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'relu_jacobian_depth_{L}.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
